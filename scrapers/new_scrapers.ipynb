{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import requests\n",
    "import string \n",
    "import numpy as np\n",
    "import nltk\n",
    "import time\n",
    "from numpy import linalg as LA\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from lda import LDA\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from alive_progress import alive_bar\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.core.utils import ChromeType\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PARENT_DIR = os.path.dirname(ROOT_DIR)\n",
    "GUARDIAN_DIR = os.path.join(ROOT_DIR, \"data\", \"Guardian.csv\")\n",
    "REUTERS_DIR = os.path.join(ROOT_DIR, \"data\", \"Reuters.csv\")\n",
    "CNN_DIR = os.path.join(PARENT_DIR, \"data\", \"CNN.csv\")\n",
    "DAILYMAIL_DIR = os.path.join(PARENT_DIR, \"data\", \"DailyMail.csv\")\n",
    "GLOVE_DIR = os.path.join(ROOT_DIR, \"glove_data\", \"results\", \"vectors.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DailyMail: \n",
    "    def __init__(self) -> None:\n",
    "        self.source = \"DailyMail\"\n",
    "\n",
    "    def fromScratch(self):\n",
    "            if not os.path.exists(DAILYMAIL_DIR):\n",
    "                self.old_data = pd.DataFrame(columns=[\"Date\", \"URL\", \"Title\", \"Text\"])\n",
    "                self.from_scratch = True\n",
    "            else:\n",
    "                self.old_data = pd.read_csv(DAILYMAIL_DIR)\n",
    "                self.from_scratch = False\n",
    "\n",
    "    def concatData(self):\n",
    "        result = pd.concat([self.old_data, self.new_data])\n",
    "        result = result.drop_duplicates(subset=[\"Text\"])\n",
    "        result = result.set_index(\"Date\")\n",
    "        result = result.sort_index(ascending=False)\n",
    "        return result\n",
    "\n",
    "    def URLFetcher(self):\n",
    "            self.urls = []\n",
    "            self.dates = []\n",
    "\n",
    "            if self.from_scratch == False:\n",
    "                last_url = self.old_data.iloc[0,1]\n",
    "            elif self.from_scratch == True:\n",
    "                last_url = \"https://www.dailymail.co.uk/news/article-10626865/Boris-plans-face-face-meeting-Biden-emergency-NATO-summit.html\"\n",
    "\n",
    "            with alive_bar(title=f\"→ {self.source}: Fetching URLs in pages\", bar=None, spinner=\"dots\", force_tty=True) as bar:\n",
    "                for page in range(0,5): # 95\n",
    "                    leading_url = \"https://www.dailymail.co.uk\"\n",
    "                    url = \"https://www.dailymail.co.uk/home/search.html?offset=\"+str(page*50)+\"&size=50&sel=site&searchPhrase=ukraine+russia&sort=recent&channel=news&type=article&days=all\"\n",
    "                    title_tag=\"sch-res-title\"\n",
    "                    exc_list=[]\n",
    "                    inc_list=[\"/news/\"]\n",
    "                    try:\n",
    "                        html_text = requests.get(url).text\n",
    "                        soup = BeautifulSoup(html_text, \"lxml\")\n",
    "                        headlines = soup.find_all(\"h3\", class_=title_tag)\n",
    "                        for headline in headlines:\n",
    "                            _ = headline.find(\"a\", href=True)\n",
    "                            url = leading_url + _[\"href\"]\n",
    "                            self.urls.append(url)\n",
    "                            if last_url == url:\n",
    "                                break\n",
    "                        if last_url == url:\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in page {page}: {e}\")\n",
    "                        pass\n",
    "                    bar()\n",
    "            self.unique_urls = list(dict.fromkeys(self.urls))\n",
    "            print(f\"→ {len(self.unique_urls)} URLs fetched successfully!\")\n",
    "\n",
    "    def articleScraper(self):\n",
    "        bodies = []\n",
    "        titles = []\n",
    "        dates = []\n",
    "        urls = []\n",
    "        rep = {\"The Mail on Sunday can reveal:\": \"\",\n",
    "        \"RELATED ARTICLES\":\"\",\n",
    "        \"Share this article\":\"\"}\n",
    "\n",
    "        def replaceAll(text, dic):\n",
    "            for i, j in dic.items():\n",
    "                text = text.replace(i, j)\n",
    "            return text\n",
    "\n",
    "        with alive_bar(len(self.unique_urls), title=f\"→ {self.source}: Article scraper\", spinner=\"dots_waves\", bar=\"smooth\", force_tty=True) as bar:\n",
    "            for url in self.unique_urls:\n",
    "                try:\n",
    "                    title_tags = [\"pg-headline\"]\n",
    "                    text_tags = [\"mol-para-with-font\"]\n",
    "                    date_box_tag = [\"article-timestamp article-timestamp-published\"]\n",
    "                    html_text = requests.get(url).text\n",
    "                    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "                    title = soup.find(\"h2\").text\n",
    "                    date_box = soup.find(\"span\", class_ = date_box_tag)\n",
    "                    date = date_box.find(\"time\")\n",
    "                    paragraphs = soup.find_all(\"p\", class_=text_tags)\n",
    "                    body =\"\"\n",
    "                    for _ in paragraphs:\n",
    "                        body += \" \" + _.text\n",
    "                    body = replaceAll(body, rep)\n",
    "                    bodies.append(\" \".join(body.split()))\n",
    "                    titles.append(title)\n",
    "                    urls.append(url)\n",
    "                    dates.append(date.get('datetime')[:10])\n",
    "                    bar()\n",
    "                except Exception as e:\n",
    "                    print(f\"URL couldn't be scraped: {url} because {e}\")\n",
    "                    pass\n",
    "        data = pd.DataFrame({\"URL\": urls, \"Date\": dates, \"Title\": titles, \"Text\": bodies})\n",
    "        self.new_data = data\n",
    "\n",
    "    def scraper(self):\n",
    "        self.fromScratch()\n",
    "        self.URLFetcher()\n",
    "        self.articleScraper()\n",
    "        data = self.concatData()\n",
    "        lenAfter = len(data) - len(self.old_data)\n",
    "        if lenAfter == 0:\n",
    "            print(f\"→ No new articles found. Total articles: {len(data)}\")\n",
    "        else:\n",
    "            print(f\"→ {lenAfter} new articles saved to {self.source}.csv! Total articles: {len(data)}\")\n",
    "        data.to_csv(DAILYMAIL_DIR, index=True)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ DailyMail: Fetching URLs in pages (!) 0 in 1.1s (0.00/s) \n",
      "→ 1 URLs fetched successfully!\n",
      "→ DailyMail: Article scraper |████████████████████████████████████████| 1/1 [100%] in 1.8s (0.56/s)                     \n",
      "→ No new articles found. Total articles: 102\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-28</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-11154...</td>\n",
       "      <td>'This guy's already dead, let him burn in hell...</td>\n",
       "      <td>This is the disgusting moment a pro-Putin war ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-28</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-11153...</td>\n",
       "      <td>Anti-Putin pensioner who torched Russian gener...</td>\n",
       "      <td>A Russian anti-war protestor who set fire to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-28</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-11153...</td>\n",
       "      <td>Nearly three-quarters of state pension will be...</td>\n",
       "      <td>Pensioners face a 'terrifying' winter as risin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-28</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-11153...</td>\n",
       "      <td>Deputy PM Dominic Raab played laser quest whil...</td>\n",
       "      <td>Deputy Prime Minister Dominic Raab enjoyed a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-28</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-11153...</td>\n",
       "      <td>Liz Truss 'mulls emergency tax cuts including ...</td>\n",
       "      <td>Lis Truss is reportedly mulling sweeping tax c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-21</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-11130...</td>\n",
       "      <td>Russia proudly shows off an Australian Bushmas...</td>\n",
       "      <td>Russia has displayed a destroyed Australian-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-21</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-11130...</td>\n",
       "      <td>Three Kremlin 'spies' are arrested after 'spra...</td>\n",
       "      <td>Three alleged Kremlin spies caught breaking in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-20</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-11130...</td>\n",
       "      <td>Daughter of Ukraine war mastermind 'is blown t...</td>\n",
       "      <td>The daughter of Vladimir Putin's so-called 'Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-20</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-11130...</td>\n",
       "      <td>EXCLUSIVE: 'Hand on heart I can just say nothi...</td>\n",
       "      <td>The rock star who was secretly videoed dancing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-20</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-11130...</td>\n",
       "      <td>Now energy prices could rocket past £6,000 a y...</td>\n",
       "      <td>Energy bills for the typical family could reac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          URL  \\\n",
       "Date                                                            \n",
       "2022-08-28  https://www.dailymail.co.uk/news/article-11154...   \n",
       "2022-08-28  https://www.dailymail.co.uk/news/article-11153...   \n",
       "2022-08-28  https://www.dailymail.co.uk/news/article-11153...   \n",
       "2022-08-28  https://www.dailymail.co.uk/news/article-11153...   \n",
       "2022-08-28  https://www.dailymail.co.uk/news/article-11153...   \n",
       "...                                                       ...   \n",
       "2022-08-21  https://www.dailymail.co.uk/news/article-11130...   \n",
       "2022-08-21  https://www.dailymail.co.uk/news/article-11130...   \n",
       "2022-08-20  https://www.dailymail.co.uk/news/article-11130...   \n",
       "2022-08-20  https://www.dailymail.co.uk/news/article-11130...   \n",
       "2022-08-20  https://www.dailymail.co.uk/news/article-11130...   \n",
       "\n",
       "                                                        Title  \\\n",
       "Date                                                            \n",
       "2022-08-28  'This guy's already dead, let him burn in hell...   \n",
       "2022-08-28  Anti-Putin pensioner who torched Russian gener...   \n",
       "2022-08-28  Nearly three-quarters of state pension will be...   \n",
       "2022-08-28  Deputy PM Dominic Raab played laser quest whil...   \n",
       "2022-08-28  Liz Truss 'mulls emergency tax cuts including ...   \n",
       "...                                                       ...   \n",
       "2022-08-21  Russia proudly shows off an Australian Bushmas...   \n",
       "2022-08-21  Three Kremlin 'spies' are arrested after 'spra...   \n",
       "2022-08-20  Daughter of Ukraine war mastermind 'is blown t...   \n",
       "2022-08-20  EXCLUSIVE: 'Hand on heart I can just say nothi...   \n",
       "2022-08-20  Now energy prices could rocket past £6,000 a y...   \n",
       "\n",
       "                                                         Text  \n",
       "Date                                                           \n",
       "2022-08-28  This is the disgusting moment a pro-Putin war ...  \n",
       "2022-08-28  A Russian anti-war protestor who set fire to a...  \n",
       "2022-08-28  Pensioners face a 'terrifying' winter as risin...  \n",
       "2022-08-28  Deputy Prime Minister Dominic Raab enjoyed a g...  \n",
       "2022-08-28  Lis Truss is reportedly mulling sweeping tax c...  \n",
       "...                                                       ...  \n",
       "2022-08-21  Russia has displayed a destroyed Australian-ma...  \n",
       "2022-08-21  Three alleged Kremlin spies caught breaking in...  \n",
       "2022-08-20  The daughter of Vladimir Putin's so-called 'Ra...  \n",
       "2022-08-20  The rock star who was secretly videoed dancing...  \n",
       "2022-08-20  Energy bills for the typical family could reac...  \n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailymail = DailyMail()\n",
    "dailymail.scraper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71a723942456804a71d025442f2ccd3a5c8db2153e1c9e51f0af23a7e755532d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
