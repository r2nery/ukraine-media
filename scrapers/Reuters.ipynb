{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alive_progress import alive_bar\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PARENT_DIR = os.path.dirname(ROOT_DIR)\n",
    "\n",
    "def replaceAll(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Scraper |████████████████████████████████████████| 2/2 [100%] in 0.9s (2.18/s)                                       \n",
      "-> 29 URLs fetched successfully!\n"
     ]
    }
   ],
   "source": [
    "urls = []\n",
    "\n",
    "num_pages = 880 # Number of pages per country (rus,ukr)\n",
    "\n",
    "with alive_bar(2*num_pages, title=\"-> Scraper\", spinner=\"dots_waves\", bar=\"smooth\", force_tty=True) as bar:\n",
    "    for page in range (1,2*(num_pages)+1):\n",
    "\n",
    "        ukr = \"https://www.reuters.com/news/archive/ukraine?view=page&page=\" + str(page) + \"&pageSize=10\"\n",
    "        rus = \"https://www.reuters.com/news/archive/russia?view=page&page=\" + str(page) + \"&pageSize=10\"\n",
    "        tags = [ukr,rus]\n",
    "\n",
    "\n",
    "        for tag in tags:\n",
    "            html_text = requests.get(tag).text\n",
    "            soup = BeautifulSoup(html_text, 'lxml')\n",
    "            headline_list = soup.find('div', class_='column1 col col-10')\n",
    "            headlines = headline_list.find_all('div', class_='story-content')\n",
    "\n",
    "            for headline in headlines:\n",
    "                page_urls = headline.find_all('a', href=True)\n",
    "                for _ in page_urls:\n",
    "                    urls.append(\"https://www.reuters.com\" + _['href'])\n",
    "            \n",
    "        bar()\n",
    "\n",
    "unique_urls = list(dict.fromkeys(urls))\n",
    "print(f\"-> {len(unique_urls)} URLs fetched successfully!\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Scraper |████████████████████████████████████████| 29/29 [100%] in 30.4s (0.95/s)                                    \n",
      "Database generated successfully!\n"
     ]
    }
   ],
   "source": [
    "bodies = []\n",
    "titles = []\n",
    "dates = []\n",
    "urls = []\n",
    "\n",
    "# Dict of undesirable substrings\n",
    "rep = {\n",
    "    \"Our Standards: The Thomson Reuters Trust Principles.\": \"\",\n",
    "    \"read more\": \"\",\n",
    "}\n",
    "\n",
    "with alive_bar(len(unique_urls), title=\"-> Scraper\", spinner=\"dots_waves\", bar=\"smooth\", force_tty=True) as bar:\n",
    "    for url in unique_urls:\n",
    "        try:\n",
    "\n",
    "            title_tags = [\"text__text__1FZLe text__dark-grey__3Ml43 text__medium__1kbOh text__heading_2__1K_hh heading__base__2T28j heading__heading_2__3Fcw5\", \"Headline-headline-2FXIq Headline-black-OogpV ArticleHeader-headline-NlAqj\"] \n",
    "            date_tags = [\"date-line__date__23Ge-\", \"ArticleHeader-date-line-3oc3Y\"]\n",
    "            text_tags = [\"text__text__1FZLe text__dark-grey__3Ml43 text__regular__2N1Xr text__large__nEccO body__base__22dCE body__large_body__FV5_X article-body__element__2p5pI\"]\n",
    "\n",
    "            html_text = requests.get(url).text\n",
    "            soup = BeautifulSoup(html_text, \"lxml\")\n",
    "\n",
    "            title = soup.find(\"h1\", class_= title_tags).text\n",
    "            date = soup.find(\"span\", class_= date_tags).text\n",
    "            paragraphs = soup.find_all(\"p\", class_= text_tags)\n",
    "            body = \"\"\n",
    "            for _ in paragraphs:\n",
    "                body += \" \" + _.text\n",
    "            \n",
    "            body = replaceAll(body, rep)\n",
    "            bodies.append(re.sub(r\"^[^-]*-\", \"\", \" \".join(body.split())))\n",
    "\n",
    "            titles.append(title)\n",
    "            dates.append(date)\n",
    "            urls.append(url)\n",
    "            bar()\n",
    "        except:\n",
    "            print(f\"URL could'nt be parsed:{url}\")\n",
    "            pass\n",
    "\n",
    "data = pd.DataFrame({\"URL\": urls, \"Date\": dates, \"Title\": titles, \"Text\": bodies})\n",
    "os.makedirs(PARENT_DIR + \"/data\", exist_ok=True)\n",
    "data.to_csv(PARENT_DIR + \"/data/Reuters.csv\", index=True, header=True)\n",
    "\n",
    "print(\"-> Database generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.reuters.com/article/us-usa-saudi-a...</td>\n",
       "      <td>July 11, 2022</td>\n",
       "      <td>EXCLUSIVE U.S. weighs resumption of offensive ...</td>\n",
       "      <td>The Biden administration is discussing the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.reuters.com/article/us-ukraine-cri...</td>\n",
       "      <td>July 11, 2022</td>\n",
       "      <td>Ukraine and Russia: What you need to know righ...</td>\n",
       "      <td>Rescue workers pulled more bodies and some su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.reuters.com/article/us-ukraine-cri...</td>\n",
       "      <td>July 11, 2022</td>\n",
       "      <td>Rescuers pull survivors from ruined Ukrainian ...</td>\n",
       "      <td>Rescuers pulled survivors on Monday from an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.reuters.com/article/syria-crisis-u...</td>\n",
       "      <td>July 11, 2022</td>\n",
       "      <td>U.N. aid to Syria from Turkey likely to contin...</td>\n",
       "      <td>The U.N. Security Council appears set to allo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.reuters.com/article/us-britain-pol...</td>\n",
       "      <td>July 11, 2022</td>\n",
       "      <td>New UK prime minister to be announced on Sept....</td>\n",
       "      <td>Britain's new prime minister will be announce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL           Date  \\\n",
       "0  https://www.reuters.com/article/us-usa-saudi-a...  July 11, 2022   \n",
       "1  https://www.reuters.com/article/us-ukraine-cri...  July 11, 2022   \n",
       "2  https://www.reuters.com/article/us-ukraine-cri...  July 11, 2022   \n",
       "3  https://www.reuters.com/article/syria-crisis-u...  July 11, 2022   \n",
       "4  https://www.reuters.com/article/us-britain-pol...  July 11, 2022   \n",
       "\n",
       "                                               Title  \\\n",
       "0  EXCLUSIVE U.S. weighs resumption of offensive ...   \n",
       "1  Ukraine and Russia: What you need to know righ...   \n",
       "2  Rescuers pull survivors from ruined Ukrainian ...   \n",
       "3  U.N. aid to Syria from Turkey likely to contin...   \n",
       "4  New UK prime minister to be announced on Sept....   \n",
       "\n",
       "                                                Text  \n",
       "0   The Biden administration is discussing the po...  \n",
       "1   Rescue workers pulled more bodies and some su...  \n",
       "2   Rescuers pulled survivors on Monday from an a...  \n",
       "3   The U.N. Security Council appears set to allo...  \n",
       "4   Britain's new prime minister will be announce...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bd6d5ee84073ea568a8475b6416df4df35e9f8587352d1cb55f8675bca2c3cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
