{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException,  StaleElementReferenceException, WebDriverException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.core.utils import ChromeType\n",
    "from alive_progress import alive_bar\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PARENT_DIR = os.path.dirname(ROOT_DIR)\n",
    "\n",
    "def check_exists(tag):\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, tag)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def replaceAll(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text\n",
    "\n",
    "# Reuters Login information\n",
    "email = \"@gmail.com\"\n",
    "password = \"@\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Launching Browser...\n",
      "-> Scraper |████████████████████████████████████████| 10/10 [100%] in 13.1s (0.76/s)                                    \n",
      "-> 79 URLs fetched successfully!\n"
     ]
    }
   ],
   "source": [
    "# Driver configChromeDriverManager(path=r\".\\\\\").install()\n",
    "s = Service(GeckoDriverManager(path=ROOT_DIR).install())\n",
    "clear_output()\n",
    "driver = webdriver.Firefox(service=s)\n",
    "WAIT = WebDriverWait(driver, 10, ignored_exceptions=(NoSuchElementException, StaleElementReferenceException))\n",
    "\n",
    "# XPath Tags\n",
    "title_tag = \"//article[@class='story ']//div[@class='story-content']//child::a\"\n",
    "\n",
    "# Scraper\n",
    "urls = []\n",
    "pgs_ukr = 5 #879\n",
    "pgs_rus = 5 #668\n",
    "\n",
    "print(\"-> Launching Browser...\")\n",
    "\n",
    "with alive_bar(pgs_ukr+pgs_rus, title=\"-> Scraper\", spinner=\"dots_waves\", bar=\"smooth\", force_tty=True) as bar:\n",
    "\n",
    "    f = open(PARENT_DIR + \"/data/ReutersURLs.csv\", \"w+\")\n",
    "    f.close()\n",
    "\n",
    "    for page in range(1, pgs_ukr+1):\n",
    "\n",
    "        reuters = \"https://www.reuters.com/news/archive/ukraine?view=page&page=\" + str(page) + \"&pageSize=10\"\n",
    "        driver.get(reuters)\n",
    "\n",
    "        titles = WAIT.until(EC.presence_of_all_elements_located((By.XPATH, title_tag)))\n",
    "        for title in titles:\n",
    "            urls.append(title.get_attribute(\"href\"))\n",
    "            with open(PARENT_DIR + \"/data/ReutersURLs.csv\",'a', newline='') as f:\n",
    "                csv.writer(f).writerow([title.get_attribute(\"href\")])\n",
    "        \n",
    "        bar()\n",
    "\n",
    "\n",
    "    for page in range(1, pgs_rus+1):\n",
    "\n",
    "        reuters = \"https://www.reuters.com/news/archive/russia?view=page&page=\" + str(page)\n",
    "        driver.get(reuters)\n",
    "\n",
    "        titles = WAIT.until(EC.presence_of_all_elements_located((By.XPATH, title_tag)))\n",
    "        for title in titles:\n",
    "            urls.append(title.get_attribute(\"href\"))\n",
    "            with open(PARENT_DIR + \"/data/ReutersURLs.csv\",'a', newline='') as f:\n",
    "                csv.writer(f).writerow([title.get_attribute(\"href\")])\n",
    "\n",
    "        bar()\n",
    "\n",
    "unique_urls = list(dict.fromkeys(urls))\n",
    "print(f\"-> {len(unique_urls)} URLs fetched successfully!\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PARENT_DIR + \"/data/ReutersURLs.csv\", newline='') as f:\n",
    "    data = [line.rstrip('\\r\\n') for line in f]\n",
    "    unique_urls = list(dict.fromkeys(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver config\n",
    "s = Service(GeckoDriverManager(path=ROOT_DIR).install())\n",
    "clear_output()\n",
    "driver = webdriver.Firefox(service=s)\n",
    "\n",
    "# Logging in\n",
    "email_tag = \"//form//input[@type='email']\"\n",
    "password_tag = \"//form//input[@type='password']\"\n",
    "sign_in_tag = \"//form//div[@class='button__container__3sgvk']\"\n",
    "main_page_check = \"//nav[@aria-label='Main navigation']\"\n",
    "\n",
    "driver.get(\"https://www.reuters.com/signin/\")\n",
    "\n",
    "driver.find_element(By.XPATH, email_tag).send_keys(email)\n",
    "driver.find_element(By.XPATH, password_tag).send_keys(password)\n",
    "driver.find_element(By.XPATH, sign_in_tag).click()\n",
    "while not check_exists(main_page_check): time.sleep(1)\n",
    "\n",
    "# Parsing news\n",
    "\n",
    "# CSS Selector Tags\n",
    "title_tag = \"//header//h1\"\n",
    "text_tag = \"//div[@class='article-body__content__17Yit paywall-article']//p[@data-testid!='Body']\"\n",
    "date_tag = \"//header//time//span[1]\"\n",
    "\n",
    "# Undesirable substrings\n",
    "rep = {\n",
    "    \"read more\": \"\",\n",
    "}\n",
    "\n",
    "# Scraper\n",
    "texts = []\n",
    "titles = []\n",
    "dates = []\n",
    "urls = []\n",
    "print(\"-> Launching Browser...\")\n",
    "\n",
    "with alive_bar(len(unique_urls), title=\"-> Scraper\", spinner=\"dots_waves\", bar=\"smooth\", force_tty=True) as bar:\n",
    "    for url in unique_urls:\n",
    "\n",
    "        driver.get(url)\n",
    "\n",
    "        title = driver.find_element(By.XPATH, title_tag).text\n",
    "\n",
    "        tempDate = driver.find_element(By.XPATH, date_tag).text\n",
    "\n",
    "        text = \"\"\n",
    "        phrases = driver.find_elements(By.XPATH, text_tag)\n",
    "        for phrase in phrases:\n",
    "            text += \" \" + phrase.text\n",
    "        text = replaceAll(text, rep)\n",
    "\n",
    "        texts.append(text)\n",
    "        titles.append(title)\n",
    "        dates.append(tempDate)\n",
    "        urls.append(url)\n",
    "\n",
    "        bar()\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "splits = np.array_split(unique_urls, 3)\n",
    "\n",
    "dict_data = {\"URL\":urls,\"Date\":dates,\"Title\": titles, \"Text\": texts}\n",
    "data = pd.DataFrame(dict_data)\n",
    "\n",
    "print(\"Database generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.reuters.com/article/us-ukraine-cri...</td>\n",
       "      <td>July 9, 2022</td>\n",
       "      <td>Russia threatens broad Ukraine offensive as U....</td>\n",
       "      <td>KYIV, July 9 (Reuters) - Ukrainian defenders ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.reuters.com/article/g20-usa-china/...</td>\n",
       "      <td>July 9, 2022</td>\n",
       "      <td>Blinken, China's Wang Yi hold talks covering U...</td>\n",
       "      <td>NUSA DUA, Indonesia, July 9 (Reuters) - U.S. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.reuters.com/article/us-britain-pol...</td>\n",
       "      <td>July 9, 2022</td>\n",
       "      <td>Two more minsters join lengthening list of can...</td>\n",
       "      <td>LONDON, July 9 (Reuters) - Two cabinet minist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.reuters.com/article/us-ukraine-cri...</td>\n",
       "      <td>July 9, 2022</td>\n",
       "      <td>Zelenskiy sacks Ukraine's envoy to Germany, ot...</td>\n",
       "      <td>KYIV, July 9 (Reuters) - Ukrainian President ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.reuters.com/article/us-ukraine-cri...</td>\n",
       "      <td>July 9, 2022</td>\n",
       "      <td>Russian forces unlikely to leave southern Ukra...</td>\n",
       "      <td>LONDON, July 9 (Reuters) - Russia is unlikely...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL          Date  \\\n",
       "0  https://www.reuters.com/article/us-ukraine-cri...  July 9, 2022   \n",
       "1  https://www.reuters.com/article/g20-usa-china/...  July 9, 2022   \n",
       "2  https://www.reuters.com/article/us-britain-pol...  July 9, 2022   \n",
       "3  https://www.reuters.com/article/us-ukraine-cri...  July 9, 2022   \n",
       "4  https://www.reuters.com/article/us-ukraine-cri...  July 9, 2022   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Russia threatens broad Ukraine offensive as U....   \n",
       "1  Blinken, China's Wang Yi hold talks covering U...   \n",
       "2  Two more minsters join lengthening list of can...   \n",
       "3  Zelenskiy sacks Ukraine's envoy to Germany, ot...   \n",
       "4  Russian forces unlikely to leave southern Ukra...   \n",
       "\n",
       "                                                Text  \n",
       "0   KYIV, July 9 (Reuters) - Ukrainian defenders ...  \n",
       "1   NUSA DUA, Indonesia, July 9 (Reuters) - U.S. ...  \n",
       "2   LONDON, July 9 (Reuters) - Two cabinet minist...  \n",
       "3   KYIV, July 9 (Reuters) - Ukrainian President ...  \n",
       "4   LONDON, July 9 (Reuters) - Russia is unlikely...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(PARENT_DIR + \"/data\", exist_ok=True)\n",
    "data.to_csv(PARENT_DIR + \"/data/Reuters.csv\", index=True, header=True)\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bd6d5ee84073ea568a8475b6416df4df35e9f8587352d1cb55f8675bca2c3cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
