{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "# The Guardian API key\n",
    "keyG = \"fad78733-31a0-4ea7-8823-ba815b578899\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions and API query setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> There are 2655 articles in 14 pages for the period and tags specified.\n"
     ]
    }
   ],
   "source": [
    "# Function that clears text of a dict of substrings\n",
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Function that returns the number of articles in the current API query page\n",
    "def numArticlesInPage(json):\n",
    "    if json[\"response\"][\"total\"] - json[\"response\"][\"startIndex\"] >= 200:\n",
    "        return 200\n",
    "    else:\n",
    "        return json[\"response\"][\"total\"] - json[\"response\"][\"startIndex\"] + 1\n",
    "\n",
    "\n",
    "# Query setup function\n",
    "def guardian(page):\n",
    "    return requests.get(\n",
    "    \"https://content.guardianapis.com/search?api-key=\" + keyG + \n",
    "    \"&from-date=2022-02-01\" + \n",
    "    \"&type=article\" + \n",
    "    \"&page=\" + str(page) + \n",
    "    \"&tag=world/ukraine\" + \n",
    "    \"&order-by=newest\" + \n",
    "    \"&show-fields=body\" + \n",
    "    \"&page-size=200\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Dict of undesirable substrings\n",
    "rep = {\n",
    "    \"Sign up to First Edition, our free daily newsletter – every weekday morning at 7am\": \"\",\n",
    "    \"Sign up to First Edition, our free daily newsletter – every weekday at 7am BST\": \"\",\n",
    "    \"Sign up to receive Guardian Australia’s fortnightly Rural Network email newsletter\": \"\",\n",
    "    \"Sign up for the Rural Network email newsletter Join the Rural Network group on Facebook to be part of the community\": \"\",\n",
    "    \"Sign up to the daily Business Today email or follow Guardian Business on Twitter at @BusinessDesk\": \"\",\n",
    "    \"Photograph:\": \"\",\n",
    "    \"Related:\": \"\",\n",
    "}\n",
    "\n",
    "# Instancing a query to fetch basic information\n",
    "json_guardian = guardian(14).json()\n",
    "numPages = json_guardian[\"response\"][\"pages\"]\n",
    "numArticles = json_guardian[\"response\"][\"total\"]\n",
    "# print(json.dumps(json_guardian, indent=2))\n",
    "\n",
    "print(f\"-> There are {numArticles} articles in {numPages} pages for the period and tags specified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> API Query |████████████████████████████████████████| 2655/2655 [100%] in 40.6s (65.46/s)                             \n",
      "-> 2655 articles fetched successfully!\n"
     ]
    }
   ],
   "source": [
    "# Instancing\n",
    "urls = []\n",
    "titles = []\n",
    "bodies = []\n",
    "dates = []\n",
    "\n",
    "# Scraper\n",
    "with alive_bar(numArticles, title=\"-> API Query\", spinner=\"dots_waves\", bar=\"smooth\", force_tty=True) as bar:\n",
    "\n",
    "    # Going through all pages available for the query\n",
    "    for page in range(1, numPages + 1):\n",
    "\n",
    "        json_guardian = guardian(page).json()\n",
    "\n",
    "        # Going through all articles in a page\n",
    "        for i in range(0, numArticlesInPage(json_guardian)):\n",
    "\n",
    "            urls.append(json_guardian[\"response\"][\"results\"][i][\"webUrl\"])\n",
    "            titles.append(json_guardian[\"response\"][\"results\"][i][\"webTitle\"])\n",
    "            dates.append(json_guardian[\"response\"][\"results\"][i][\"webPublicationDate\"])\n",
    "            soup = BeautifulSoup(json_guardian[\"response\"][\"results\"][i][\"fields\"][\"body\"], \"html.parser\").get_text()\n",
    "\n",
    "            soup = replace_all(soup, rep)  # replacing substrings\n",
    "            soup = re.sub(r\"[\\t\\r\\n]\", \"\", soup)  # removing line breaks\n",
    "            bodies.append(soup)\n",
    "            bar()\n",
    "\n",
    "# Transforming fetched info to dataframe\n",
    "dict_data = {\"URL\": urls, \"Date\": dates, \"Title\": titles, \"Text\": bodies}\n",
    "data = pd.DataFrame(dict_data)\n",
    "\n",
    "# Saving to csv\n",
    "os.makedirs(os.getcwd() + \"/data\", exist_ok=True)\n",
    "data.to_csv(\"data/guardian.csv\", index=True, header=True)\n",
    "\n",
    "print(f\"-> {len(data)} articles fetched successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bd6d5ee84073ea568a8475b6416df4df35e9f8587352d1cb55f8675bca2c3cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
